{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyO8TUKxz2qm0v6dqUgjYGGV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradyot-09/DL-Reproducibility-Project/blob/master/CNNModel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ggZwuHLh0DnF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pytorch basic functions/classes\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import torchvision functions/classes for MNIST import and data loaders\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set device on which code is run\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5siRsiAE0H9i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transform from PIL image to tensor and normalize to 1x768 pixels\n",
        "transform = transforms.Compose([\n",
        "  transforms.Resize(28),\n",
        "  transforms.CenterCrop(28),\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5, ), (0.5, ))\n",
        "])\n",
        "\n",
        "# Set batch size for data loaders\n",
        "batch_size = 32\n",
        "\n",
        "# (Down)load training set\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# (Down)load test set\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWr-7u_20KcC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define CNN model and its layers\n",
        "class CNNModel(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size=128, dropout=0.25, hidden_dropout=0.5):\n",
        "        super(CNNModel, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(32,64, kernel_size=5)\n",
        "        self.dropout1 = nn.Dropout2d(dropout)\n",
        "        self.dropout2 = nn.Dropout2d(hidden_dropout)\n",
        "        self.fc1 = nn.Linear(6400, hidden_size)\n",
        "        self.fc2 = nn.Linear(hidden_size, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = F.max_pool2d(x, 2)\n",
        "        x = self.dropout1(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        return self.fc2(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XV8-u1FI0g4e",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "7852d59b-4a9e-42eb-a869-ac8bcb7298c6"
      },
      "source": [
        "# Setup model and move it to the GPU\n",
        "net = CNNModel()\n",
        "net.to(device)\n",
        "\n",
        "# Set up loss function and optimizer: \n",
        "#     using cross entropy loss because it's better for classification task\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "#optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9)\n",
        "optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=0.001)\n",
        "\n",
        "# Run over 100 epochs (1 epoch = visited all items in dataset)\n",
        "for epoch in range(100): #200 for SGD reaches 0.002 loss\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        \n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs = inputs.to(device)\n",
        "        target = labels.to(device).long()\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += len(data)\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    # print every epoch\n",
        "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save model after having finished training\n",
        "PATH = './mnist_dropout_100_epoch.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "print('Saved Model')"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] loss: 0.172\n",
            "[2] loss: 0.062\n",
            "[3] loss: 0.046\n",
            "[4] loss: 0.040\n",
            "[5] loss: 0.035\n",
            "[6] loss: 0.032\n",
            "[7] loss: 0.029\n",
            "[8] loss: 0.028\n",
            "[9] loss: 0.026\n",
            "[10] loss: 0.025\n",
            "[11] loss: 0.023\n",
            "[12] loss: 0.023\n",
            "[13] loss: 0.021\n",
            "[14] loss: 0.022\n",
            "[15] loss: 0.021\n",
            "[16] loss: 0.020\n",
            "[17] loss: 0.020\n",
            "[18] loss: 0.020\n",
            "[19] loss: 0.019\n",
            "[20] loss: 0.018\n",
            "[21] loss: 0.018\n",
            "[22] loss: 0.017\n",
            "[23] loss: 0.018\n",
            "[24] loss: 0.017\n",
            "[25] loss: 0.018\n",
            "[26] loss: 0.016\n",
            "[27] loss: 0.017\n",
            "[28] loss: 0.016\n",
            "[29] loss: 0.017\n",
            "[30] loss: 0.016\n",
            "[31] loss: 0.016\n",
            "[32] loss: 0.016\n",
            "[33] loss: 0.016\n",
            "[34] loss: 0.015\n",
            "[35] loss: 0.015\n",
            "[36] loss: 0.015\n",
            "[37] loss: 0.015\n",
            "[38] loss: 0.015\n",
            "[39] loss: 0.016\n",
            "[40] loss: 0.015\n",
            "[41] loss: 0.015\n",
            "[42] loss: 0.014\n",
            "[43] loss: 0.015\n",
            "[44] loss: 0.014\n",
            "[45] loss: 0.014\n",
            "[46] loss: 0.013\n",
            "[47] loss: 0.015\n",
            "[48] loss: 0.014\n",
            "[49] loss: 0.015\n",
            "[50] loss: 0.014\n",
            "[51] loss: 0.014\n",
            "[52] loss: 0.014\n",
            "[53] loss: 0.014\n",
            "[54] loss: 0.015\n",
            "[55] loss: 0.014\n",
            "[56] loss: 0.014\n",
            "[57] loss: 0.014\n",
            "[58] loss: 0.014\n",
            "[59] loss: 0.014\n",
            "[60] loss: 0.014\n",
            "[61] loss: 0.013\n",
            "[62] loss: 0.014\n",
            "[63] loss: 0.014\n",
            "[64] loss: 0.014\n",
            "[65] loss: 0.014\n",
            "[66] loss: 0.014\n",
            "[67] loss: 0.013\n",
            "[68] loss: 0.014\n",
            "[69] loss: 0.014\n",
            "[70] loss: 0.013\n",
            "[71] loss: 0.014\n",
            "[72] loss: 0.013\n",
            "[73] loss: 0.014\n",
            "[74] loss: 0.013\n",
            "[75] loss: 0.013\n",
            "[76] loss: 0.013\n",
            "[77] loss: 0.013\n",
            "[78] loss: 0.013\n",
            "[79] loss: 0.013\n",
            "[80] loss: 0.013\n",
            "[81] loss: 0.013\n",
            "[82] loss: 0.012\n",
            "[83] loss: 0.013\n",
            "[84] loss: 0.013\n",
            "[85] loss: 0.013\n",
            "[86] loss: 0.013\n",
            "[87] loss: 0.013\n",
            "[88] loss: 0.013\n",
            "[89] loss: 0.013\n",
            "[90] loss: 0.013\n",
            "[91] loss: 0.013\n",
            "[92] loss: 0.013\n",
            "[93] loss: 0.013\n",
            "[94] loss: 0.013\n",
            "[95] loss: 0.013\n",
            "[96] loss: 0.013\n",
            "[97] loss: 0.013\n",
            "[98] loss: 0.013\n",
            "[99] loss: 0.013\n",
            "[100] loss: 0.013\n",
            "Finished Training\n",
            "Saved Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z_cGzny4acEs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Instantiate model and load saved network parameters\n",
        "net = CNNModel().to(device)\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# Run model on test set and determine accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for (inputs, labels)) in testloader:\n",
        "        inputs = inputs.to(device)\n",
        "        target = labels.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        _, target = torch.max(target.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "# Output model accuracy to user\n",
        "print('Accuracy of the network on the 10000 test images: %d %% (%d wrong out of %d)' % (\n",
        "    100 * correct / total, total - correct, total))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}