{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "distillation.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/pradyot-09/DL-Reproducibility-Project/blob/master/distillation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E20iEpB1qB_U",
        "colab_type": "text"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKXEF8f3moEd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import pytorch basic functions/classes\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "# Import torchvision functions/classes for MNIST import and data loaders\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Set device on which code is run\n",
        "device = 'cuda'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jl08sOn-p-WI",
        "colab_type": "text"
      },
      "source": [
        "Defining support functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQZ1UPkh2iN-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define support function used to convert label to one-hot encoded tensor\n",
        "def convert_labels(labels):\n",
        "    target = torch.zeros([len(labels), 10], dtype=torch.float32)\n",
        "    for i, l in enumerate(labels):\n",
        "      target[i][l] = 1.0\n",
        "    return target"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MepCPdkTqMD3",
        "colab_type": "text"
      },
      "source": [
        "Define our network model (the hidden layers size is specified through the constructor)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCFrlhvun-U_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define MLP model and its layers\n",
        "class Model(nn.Module):\n",
        "\n",
        "    def __init__(self, hidden_size=1200, dropout=0.0, hidden_dropout=0.0):\n",
        "        super(Model, self).__init__()\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.hidden1 = nn.Linear(784, hidden_size, bias=True)\n",
        "        self.hidden1_dropout = nn.Dropout(hidden_dropout)\n",
        "        self.hidden2 = nn.Linear(hidden_size, hidden_size, bias=True)\n",
        "        self.hidden2_dropout = nn.Dropout(hidden_dropout)\n",
        "        self.hidden3 = nn.Linear(hidden_size, 10, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        x = self.dropout(x)\n",
        "        x = F.relu(self.hidden1(x))\n",
        "        x = self.hidden1_dropout(x)\n",
        "        x = F.relu(self.hidden2(x))\n",
        "        x = self.hidden2_dropout(x)\n",
        "        x = self.hidden3(x)\n",
        "        return x#, F.softmax(x)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwzMAeT7qZCW",
        "colab_type": "text"
      },
      "source": [
        "Downloading MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONsjY_Fmpe0t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define transform from PIL image to tensor and normalize to 1x768 pixels\n",
        "transform = transforms.Compose([\n",
        "  transforms.ToTensor(),\n",
        "  transforms.Normalize((0.5,), (0.5,))\n",
        "])\n",
        "\n",
        "# Set batch size for data loaders\n",
        "batch_size = 128\n",
        "\n",
        "# (Down)load training set\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "\n",
        "# (Down)load test set\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tdksm3J5qfzu",
        "colab_type": "text"
      },
      "source": [
        "Training the Deep Teacher Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rOCDtvFrTa4",
        "colab_type": "code",
        "outputId": "eebc3f58-4783-439c-cd8f-179b3d3955d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# Setup model and move it to the GPU\n",
        "net = Model(dropout=0.2, hidden_dropout=0.5)\n",
        "net.to(device)\n",
        "\n",
        "# Set up loss function and optimizer: \n",
        "#     using cross entropy loss because it's better for classification task\n",
        "\n",
        "learning_rate = 0.011\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr= learning_rate, momentum=0.9)\n",
        "#optimizer = torch.optim.Adam(net.parameters(), lr=0.0001, weight_decay=0.00001)\n",
        "\n",
        "# Run over 100 epochs (1 epoch = visited all items in dataset)\n",
        "for epoch in range(100):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "\n",
        "    if(epoch%20 == 0):\n",
        "\n",
        "      learning_rate = learning_rate - (0.001) # or maybe decrease by (learning_rate * 0.1)\n",
        "      optimizer = optim.SGD(net.parameters(), lr= learning_rate, momentum=0.9)\n",
        "\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        \n",
        "\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = torch.flatten(inputs, start_dim=1).to(device)\n",
        "\n",
        "        # This for not cross entropy\n",
        "        #target = convert_labels(labels).to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        target = labels.to(device).long()\n",
        "        loss = criterion(outputs, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += len(data)\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    # print every epoch\n",
        "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save model after having finished training\n",
        "PATH = './mnist_dropout_100_epoch.pth'\n",
        "torch.save(net.state_dict(), PATH)\n",
        "\n",
        "print('Saved Model')"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] loss: 0.316\n",
            "[2] loss: 0.157\n",
            "[3] loss: 0.124\n",
            "[4] loss: 0.105\n",
            "[5] loss: 0.094\n",
            "[6] loss: 0.086\n",
            "[7] loss: 0.080\n",
            "[8] loss: 0.074\n",
            "[9] loss: 0.070\n",
            "[10] loss: 0.066\n",
            "[11] loss: 0.063\n",
            "[12] loss: 0.059\n",
            "[13] loss: 0.057\n",
            "[14] loss: 0.054\n",
            "[15] loss: 0.053\n",
            "[16] loss: 0.050\n",
            "[17] loss: 0.049\n",
            "[18] loss: 0.047\n",
            "[19] loss: 0.046\n",
            "[20] loss: 0.045\n",
            "[21] loss: 0.042\n",
            "[22] loss: 0.040\n",
            "[23] loss: 0.041\n",
            "[24] loss: 0.040\n",
            "[25] loss: 0.038\n",
            "[26] loss: 0.038\n",
            "[27] loss: 0.037\n",
            "[28] loss: 0.036\n",
            "[29] loss: 0.036\n",
            "[30] loss: 0.034\n",
            "[31] loss: 0.034\n",
            "[32] loss: 0.033\n",
            "[33] loss: 0.033\n",
            "[34] loss: 0.032\n",
            "[35] loss: 0.031\n",
            "[36] loss: 0.031\n",
            "[37] loss: 0.030\n",
            "[38] loss: 0.029\n",
            "[39] loss: 0.029\n",
            "[40] loss: 0.028\n",
            "[41] loss: 0.028\n",
            "[42] loss: 0.026\n",
            "[43] loss: 0.026\n",
            "[44] loss: 0.025\n",
            "[45] loss: 0.025\n",
            "[46] loss: 0.026\n",
            "[47] loss: 0.025\n",
            "[48] loss: 0.025\n",
            "[49] loss: 0.024\n",
            "[50] loss: 0.024\n",
            "[51] loss: 0.024\n",
            "[52] loss: 0.024\n",
            "[53] loss: 0.023\n",
            "[54] loss: 0.023\n",
            "[55] loss: 0.022\n",
            "[56] loss: 0.022\n",
            "[57] loss: 0.023\n",
            "[58] loss: 0.021\n",
            "[59] loss: 0.022\n",
            "[60] loss: 0.022\n",
            "[61] loss: 0.021\n",
            "[62] loss: 0.020\n",
            "[63] loss: 0.021\n",
            "[64] loss: 0.020\n",
            "[65] loss: 0.020\n",
            "[66] loss: 0.019\n",
            "[67] loss: 0.019\n",
            "[68] loss: 0.020\n",
            "[69] loss: 0.019\n",
            "[70] loss: 0.018\n",
            "[71] loss: 0.018\n",
            "[72] loss: 0.019\n",
            "[73] loss: 0.018\n",
            "[74] loss: 0.018\n",
            "[75] loss: 0.018\n",
            "[76] loss: 0.018\n",
            "[77] loss: 0.017\n",
            "[78] loss: 0.017\n",
            "[79] loss: 0.016\n",
            "[80] loss: 0.018\n",
            "[81] loss: 0.016\n",
            "[82] loss: 0.016\n",
            "[83] loss: 0.016\n",
            "[84] loss: 0.016\n",
            "[85] loss: 0.015\n",
            "[86] loss: 0.015\n",
            "[87] loss: 0.015\n",
            "[88] loss: 0.016\n",
            "[89] loss: 0.016\n",
            "[90] loss: 0.015\n",
            "[91] loss: 0.016\n",
            "[92] loss: 0.015\n",
            "[93] loss: 0.015\n",
            "[94] loss: 0.015\n",
            "[95] loss: 0.015\n",
            "[96] loss: 0.014\n",
            "[97] loss: 0.015\n",
            "[98] loss: 0.014\n",
            "[99] loss: 0.014\n",
            "[100] loss: 0.013\n",
            "Finished Training\n",
            "Saved Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W2Xqz-DlqmCT",
        "colab_type": "text"
      },
      "source": [
        "Run Deep Teacher model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gI5BL9YF2dzp",
        "colab_type": "code",
        "outputId": "d15d0ead-6f2c-4773-a9b7-a4918fe4bbfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Instantiate model and load saved network parameters\n",
        "net = Model().to(device)\n",
        "net.load_state_dict(torch.load(PATH))\n",
        "\n",
        "# Run model on test set and determine accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs = torch.flatten(inputs, start_dim=1).to(device)\n",
        "        target = convert_labels(labels).to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        _, target = torch.max(target.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "# Output model accuracy to user\n",
        "print('Accuracy of the network on the 10000 test images: %d %% (%d wrong out of %d)' % (\n",
        "    100 * correct / total, total - correct, total))"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 98 % (129 wrong out of 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bigRhVYyqvL1",
        "colab_type": "text"
      },
      "source": [
        "Train student model to mimic the teacher"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VOPgLsQ6D3Lj",
        "colab_type": "code",
        "outputId": "4acfb453-5432-4c5e-f04d-5289930b549d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import numpy as np\n",
        "# Custom student loss: linear combination of 2 cross-entropy losses\n",
        "#     The first one between student output and hard labels\n",
        "#     The second one between student output and soft labels from teacher\n",
        "\n",
        "def student_loss(outputA, targetA, outputB, targetB, weight):\n",
        "\n",
        "    #loss = torch.mean((weight*(outputA - targetA)**2) + (1-weight)*(outputB-targetB)**2)\n",
        "\n",
        "    loss = weight*(F.cross_entropy(outputA, targetA)) + (1-weight)*(F.cross_entropy(outputB, targetB))\n",
        "\n",
        "    return loss\n",
        "\n",
        "# Setup student model and move it to the GPU\n",
        "student_net = Model(hidden_size = 800)\n",
        "student_net.to(device)\n",
        "\n",
        "# Set up loss function and optimizer\n",
        "\n",
        "optimizer = optim.SGD(student_net.parameters(), lr=0.001, momentum=0.9)\n",
        "#optimizer = torch.optim.Adam(student_net.parameters(), lr=0.0001)\n",
        "\n",
        "# Run over 100 epochs (1 epoch = visited all items in dataset)\n",
        "for epoch in range(100):\n",
        "    running_loss = 0.0\n",
        "    total = 0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = torch.flatten(inputs, start_dim=1).to(device)\n",
        "        target = labels.to(device).long() #convert_labels(labels).to(device)\n",
        "        \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # Set temperature and the weights for losses linear combination\n",
        "        w = 0.3\n",
        "        T = 20\n",
        "\n",
        "        # Compute soft labels using deep teacher model previously trained\n",
        "        outputs_teacher = net(inputs)\n",
        "        soft_labels = F.softmax(outputs_teacher/T, dim = 1)\n",
        "\n",
        "        # Abomination to obtain hard_labels for custom cross entropy loss\n",
        "        teacher_hard_labels = torch.from_numpy(np.array([np.argmax(l.cpu().detach().numpy()) for l in soft_labels])).to(device).long()\n",
        "\n",
        "        # Student forward + backward + optimize\n",
        "        outputs_stud = student_net(inputs)\n",
        "        loss = student_loss(outputs_stud, target, outputs_stud, teacher_hard_labels, w)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total += len(data)\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "    # print every epoch\n",
        "    print('[%d] loss: %.3f' % (epoch + 1, running_loss / total))\n",
        "\n",
        "print('Finished Training')\n",
        "\n",
        "# Save model after having finished training\n",
        "STUD_PATH = './mnist_student_100_epoch.pth'\n",
        "torch.save(student_net.state_dict(), STUD_PATH)\n",
        "\n",
        "print('Saved Model')"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1] loss: 0.640\n",
            "[2] loss: 0.227\n",
            "[3] loss: 0.181\n",
            "[4] loss: 0.163\n",
            "[5] loss: 0.152\n",
            "[6] loss: 0.143\n",
            "[7] loss: 0.135\n",
            "[8] loss: 0.129\n",
            "[9] loss: 0.123\n",
            "[10] loss: 0.116\n",
            "[11] loss: 0.111\n",
            "[12] loss: 0.105\n",
            "[13] loss: 0.101\n",
            "[14] loss: 0.095\n",
            "[15] loss: 0.091\n",
            "[16] loss: 0.087\n",
            "[17] loss: 0.083\n",
            "[18] loss: 0.079\n",
            "[19] loss: 0.076\n",
            "[20] loss: 0.073\n",
            "[21] loss: 0.070\n",
            "[22] loss: 0.067\n",
            "[23] loss: 0.064\n",
            "[24] loss: 0.062\n",
            "[25] loss: 0.059\n",
            "[26] loss: 0.057\n",
            "[27] loss: 0.055\n",
            "[28] loss: 0.053\n",
            "[29] loss: 0.051\n",
            "[30] loss: 0.050\n",
            "[31] loss: 0.048\n",
            "[32] loss: 0.046\n",
            "[33] loss: 0.045\n",
            "[34] loss: 0.043\n",
            "[35] loss: 0.042\n",
            "[36] loss: 0.041\n",
            "[37] loss: 0.039\n",
            "[38] loss: 0.038\n",
            "[39] loss: 0.037\n",
            "[40] loss: 0.036\n",
            "[41] loss: 0.035\n",
            "[42] loss: 0.034\n",
            "[43] loss: 0.033\n",
            "[44] loss: 0.032\n",
            "[45] loss: 0.031\n",
            "[46] loss: 0.030\n",
            "[47] loss: 0.029\n",
            "[48] loss: 0.029\n",
            "[49] loss: 0.028\n",
            "[50] loss: 0.027\n",
            "[51] loss: 0.026\n",
            "[52] loss: 0.026\n",
            "[53] loss: 0.025\n",
            "[54] loss: 0.024\n",
            "[55] loss: 0.024\n",
            "[56] loss: 0.023\n",
            "[57] loss: 0.022\n",
            "[58] loss: 0.022\n",
            "[59] loss: 0.021\n",
            "[60] loss: 0.021\n",
            "[61] loss: 0.020\n",
            "[62] loss: 0.020\n",
            "[63] loss: 0.019\n",
            "[64] loss: 0.019\n",
            "[65] loss: 0.018\n",
            "[66] loss: 0.018\n",
            "[67] loss: 0.018\n",
            "[68] loss: 0.017\n",
            "[69] loss: 0.017\n",
            "[70] loss: 0.016\n",
            "[71] loss: 0.016\n",
            "[72] loss: 0.015\n",
            "[73] loss: 0.015\n",
            "[74] loss: 0.015\n",
            "[75] loss: 0.014\n",
            "[76] loss: 0.014\n",
            "[77] loss: 0.014\n",
            "[78] loss: 0.013\n",
            "[79] loss: 0.013\n",
            "[80] loss: 0.013\n",
            "[81] loss: 0.013\n",
            "[82] loss: 0.012\n",
            "[83] loss: 0.012\n",
            "[84] loss: 0.012\n",
            "[85] loss: 0.011\n",
            "[86] loss: 0.011\n",
            "[87] loss: 0.011\n",
            "[88] loss: 0.011\n",
            "[89] loss: 0.010\n",
            "[90] loss: 0.010\n",
            "[91] loss: 0.010\n",
            "[92] loss: 0.010\n",
            "[93] loss: 0.010\n",
            "[94] loss: 0.009\n",
            "[95] loss: 0.009\n",
            "[96] loss: 0.009\n",
            "[97] loss: 0.009\n",
            "[98] loss: 0.009\n",
            "[99] loss: 0.008\n",
            "[100] loss: 0.008\n",
            "Finished Training\n",
            "Saved Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G8FmA6zWq2wW",
        "colab_type": "text"
      },
      "source": [
        "Running student model on test set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s1fxqFeILgTp",
        "colab_type": "code",
        "outputId": "3a611af0-0fd5-4037-da24-40c3090f04bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "stud_net = Model(hidden_size = 800).to(device)\n",
        "stud_net.load_state_dict(torch.load(STUD_PATH))\n",
        "\n",
        "# Run model on test set and determine accuracy\n",
        "correct = 0\n",
        "total = 0\n",
        "with torch.no_grad():\n",
        "    for data in testloader:\n",
        "        inputs, labels = data\n",
        "        inputs = torch.flatten(inputs, start_dim=1).to(device)\n",
        "        target = convert_labels(labels).to(device)\n",
        "        outputs = stud_net(inputs)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        _, target = torch.max(target.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "\n",
        "# Output model accuracy to user\n",
        "print('Accuracy of the network on the 10000 test images: %d %% (%d wrong out of %d)' % (\n",
        "    100 * correct / total, total - correct, total))"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy of the network on the 10000 test images: 97 % (203 wrong out of 10000)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}